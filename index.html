<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Final Project Proposal</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Altering Surface BRDFs in Images via cGAN</h1>
<h3 align="middle">Hong Jun Jeon, 25969101</h3>
<h3 align="middle">Yiqi (Eric) Hou, 3031846767</h3>
<h3 align="middle">Jesse Ou, 3032141165</h3>
<br><br>
  <div align="center">
    <table style="width=100%">
      <tr>
        <td align="middle">
        <img src="Images/GAN.png" width="580px" />
      </tr>
    </table>
  </div>

<div class="padded">
  <h2 align="middle">Our Idea</h2>

    <p>While .dae files that describe scenes of interest are incredibly descriptive, they are not plentiful. Images, while less descriptive, are ubiquitous. It would be interesting and useful if we could alter the BRDFs of arbitrary objects in our images. We can change a picture of a mug from a lambertian brdf to a glossy one (and vice versa). It could also improve 3D reconstruction via binocular stereopsis because algorithms for finding corresponding points assume that objects in the scene have lambertian surface brdfs. While this may be ambitious (and we have a backup plan), ultimately we hope to produce a project that alters/improves a commodity that is prevalent in everyoneâ€™s life: an image file.</p>
  <h2 align="middle">Preliminary Results:</h2>
    <h3 align="middle"> CycleGAN Woes: </h3>
    <p> CycleGAN is a recently proposed idea that takes two thematic datasets of images and applies a style transfer between the two. It produced remarkable results in changing horses to zebras and vice versa, applying Monet/Van Gogh style artistry to normal camera images, and infilling crude facades of buildings. We tried using CycleGAN to change glass balls into basketballs, a BRDF transfer from glass to lambertian. One noticable issue was that while the backgrounds between horses and zebras were pretty similar (fields), the backgrounds of our basketballs and our glass balls were completely distinct. As a result, the GAN didn't seem to learn the association between the Glass Ball and the Basketball. In the example below, the process from glass to basketball (left), not much about the ball changes. Rather, the background changes. For basketball to glass ball, the ball just masks into the surroundings and turns green, likely because much of our dataset was glass balls in a nature landscape. Moving forward, we will alter our architecture to make the association between glass and basketball more deliberate.</p>
    <div align="center">
      <table style="width=100%">
        <tr>
          <td align="middle">
          <img src="Images/CycleGAN.png" width="580px" />
        </tr>
      </table>
    </div>
    <h3 align="middle"> Pix2Pix Progress: </h3>
      <p> We will likely move forward with the pix2pix paradigm which involves a cGAN trained on PAIRED image data. In all of this, we wish to address the deliberate association of objects we wish to alter in the scene. Currently, we are generating a dataset of paired images (input, output) where the output is an original image of a ball and the output is the same image but with the ball removed (blackened out). This procedure was done using OpenCV's implementation of Hough Circles, a technique that looks for circles in images. Below are some examples of input/output pairs processed by this algorithm.</p>
    <div align="center">
      <table style="width=100%">
        <tr>
          <td align="middle">
          <img src="Images/HoughCircles.png" width="580px" />
        </tr>
      </table>
    </div>
    <h3 align="middle"> Plan Moving Forward: </h3>
      <p>-Firstly, we will collect and produce more image pairs for the pix2pix framework as described above. Then, we will train the pix2pix network on our datasets and examine the results.</p>
      <p>-If the above produces unsatisfactory results, we can try to even further deliberate the object we wish to alter. We can provide a region proposal with each image (some bounding box) as an input to make the assotiation as clear as possible.</p>
      <P>-We still wish to alter the BRDFs of arbitrary objects so we will likely use the above bounding region proposal and train on images generated by pathtracers. We are having trouble using online pathtracers so a fallback is downloading many more .exr files and using them in the backdrop when rendering spheres of different brdfs. </p>
    <h3 align="middle"> PPT and Video </h3>
    <a href="https://docs.google.com/presentation/d/1LQGJmR4-aPc1ka17HGZ1GKergYKXEPKvlx5Q1FdXq_8/edit?usp=sharing"> PPT Presentation </a>
</div>

</body>
</html>